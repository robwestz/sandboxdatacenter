{
  "checkpoint_id": "parsed_spec",
  "session_id": "20251211_002406",
  "timestamp": "2025-12-11T00:24:06.262445",
  "state": {
    "project_spec": "ProjectSpecification(name='.rapidcontext.yml', description='```yaml', type=<ProjectType.CUSTOM: 'custom'>, complexity=<ComplexityLevel.MODERATE: 'moderate'>, paradigm=<OrchestrationParadigm.AUTO: 'auto'>, objectives=['Build a working system'], features={'core': ['Basic functionality'], 'optional': []}, architecture={}, technical={}, quality={}, output=[], tech_stack=['React', 'Python', 'Fastapi', 'Node', 'Typescript', 'Postgresql', 'Redis', 'Docker', 'Kubernetes'], raw_spec='# RAPID CONTEXT - REVOLUTIONARY CODEBASE UNDERSTANDING SYSTEM\\n\\n```yaml\\n_meta:\\n  paradigm: \"neural\"                          # Pattern recognition for code analysis\\n  orchestration_style: \"aggressive\"           # Maximum speed\\n  quality_tolerance: \"standard\"               # Balance speed vs accuracy\\n  optimization_rounds: 2                      # Quick refinement\\n  learning_enabled: true                      # Learn from analysis patterns\\n  token_efficiency: \"maximum\"                 # Critical requirement\\n\\n_constraints:\\n  max_agents: 30                              # Lightweight, focused team\\n  max_build_time: \"10 minutes\"                # Ultra-fast delivery\\n  target_loc: \"2000-3000\"                     # Compact, efficient code\\n  min_test_coverage: 80                       # Reliable but not excessive\\n  token_budget: \"minimal\"                     # Core innovation constraint\\n\\n_behaviors:\\n  on_analysis: \"spawn_pattern_recognizer\"     # Identify code patterns instantly\\n  on_discovery: \"spawn_indexer\"               # Build structural map\\n  on_understanding: \"spawn_suggestion_engine\" # Generate improvement ideas\\n  on_completion: \"cache_learnings\"            # Reuse knowledge\\n\\nproject:\\n  name: \"Rapid Context\"\\n  tagline: \"Understand Any Codebase in Seconds, Not Minutes\"\\n  type: \"cli_tool_with_library\"\\n  market: \"developers_and_ai_agents\"\\n```\\n\\n---\\n\\n## PRIMARY DIRECTIVE\\n\\nBuild an **ultra-fast, token-efficient codebase analysis tool** that revolutionizes how AI agents understand code repositories. This tool must complete analysis in **seconds instead of minutes** by using intelligent sampling, pattern recognition, and structural inference rather than exhaustive reading.\\n\\n**Core Innovation:**\\n- Traditional `/init`: Reads everything, takes 2-5 minutes, uses 50k+ tokens\\n- **Rapid Context**: Samples intelligently, takes 10-30 seconds, uses <5k tokens\\n- Provides 80% of the value at 10% of the cost\\n\\n---\\n\\n## PROBLEM STATEMENT\\n\\n**Current Pain Points:**\\n1. **Claude Code\\'s /init is slow** - Takes minutes to analyze codebases\\n2. **Token inefficient** - Burns through context budget before actual work\\n3. **No incremental understanding** - Must re-analyze on every session\\n4. **Missing gap analysis** - Doesn\\'t highlight what\\'s incomplete/broken\\n5. **No actionable suggestions** - Just describes, doesn\\'t propose improvements\\n\\n**Our Solution:**\\nA lightweight CLI tool that:\\n- Analyzes folder structure in <5 seconds\\n- Identifies file purposes through pattern matching (not full reads)\\n- Detects missing components via architectural inference\\n- Generates top 10 actionable ideas using existing code patterns\\n- Outputs concise markdown suitable for LLM context (<3k tokens)\\n\\n---\\n\\n## CORE FEATURES\\n\\n### Feature 1: Lightning-Fast Structure Analysis (5 agents)\\n\\n**What:** Map entire codebase structure without reading every file\\n\\n**How:**\\n```yaml\\nStrategy: Smart Sampling\\n  - Read directory tree (instant)\\n  - Identify file types by extension\\n  - Sample 1 file per directory type (e.g., one .tsx, one .py)\\n  - Infer patterns from samples\\n  - Use naming conventions to guess purposes\\n\\nTechniques:\\n  - Convention detection: (src/, lib/, tests/, docs/)\\n  - Framework detection: (package.json \u2192 Node, requirements.txt \u2192 Python)\\n  - Pattern matching: (*_test.py \u2192 test file, index.* \u2192 entry point)\\n  - Structural inference: (routes/ \u2192 routing, components/ \u2192 UI)\\n```\\n\\n**Output Example:**\\n```markdown\\n## Structure Map\\n- Framework: React + FastAPI (detected from package.json + requirements.txt)\\n- Entry Points: src/index.tsx, backend/main.py\\n- Components: 23 React components in src/components/\\n- API Endpoints: 8 routes in backend/routes/\\n- Tests: 15 test files (Jest + Pytest)\\n- Missing: Docker setup, CI/CD config\\n```\\n\\n### Feature 2: Purpose Inference Engine (8 agents)\\n\\n**What:** Understand what each file/folder does WITHOUT reading full content\\n\\n**How:**\\n```yaml\\nSmart Analysis:\\n  1. Read first 10 lines of each file type sample\\n  2. Extract imports/exports\\n  3. Identify patterns:\\n     - Class definitions \u2192 Object models\\n     - Function signatures \u2192 API contracts\\n     - Import statements \u2192 Dependencies\\n  4. Cross-reference to build understanding\\n\\nExample:\\n  File: user_service.py\\n  First 10 lines: \"from fastapi import APIRouter\\\\nfrom .models import User\"\\n  Inference: \"User management API service using FastAPI models\"\\n```\\n\\n**Output Example:**\\n```markdown\\n## Purpose Analysis\\n- `src/components/UserList.tsx` - UI component for displaying user tables\\n- `backend/services/auth.py` - JWT authentication service\\n- `backend/models/user.py` - User database model (SQLAlchemy)\\n- `lib/utils/validation.py` - Input validation utilities\\n```\\n\\n### Feature 3: Gap Detection System (5 agents)\\n\\n**What:** Identify what\\'s MISSING for system to be complete/functional\\n\\n**How:**\\n```yaml\\nArchitectural Patterns:\\n  Web App Expected:\\n    - Frontend, Backend, Database, Tests, Deployment\\n\\n  Check Each Layer:\\n    \u2713 Frontend exists \u2192 src/\\n    \u2713 Backend exists \u2192 backend/\\n    \u2717 Database migrations missing \u2192 No migrations/ folder\\n    \u25b3 Tests incomplete \u2192 Only 60% of files have test counterparts\\n    \u2717 Deployment missing \u2192 No Dockerfile, docker-compose.yml\\n    \u2717 Documentation incomplete \u2192 No API docs, outdated README\\n\\n  Cross-Reference Patterns:\\n    - If auth.py exists but no tests/test_auth.py \u2192 Missing auth tests\\n    - If User model exists but no migrations \u2192 Missing user table migration\\n    - If API routes but no OpenAPI spec \u2192 Missing API documentation\\n```\\n\\n**Output Example:**\\n```markdown\\n## Missing Components\\n1. **Database Migrations** - Models exist but no migration system\\n2. **API Documentation** - 8 endpoints lack OpenAPI/Swagger specs\\n3. **Error Handling** - No global error handler in FastAPI\\n4. **Docker Setup** - No containerization for deployment\\n5. **CI/CD Pipeline** - No GitHub Actions or similar\\n6. **Test Coverage** - Only 60% of backend code has tests\\n7. **Logging** - No structured logging system\\n8. **Monitoring** - No health check endpoints\\n```\\n\\n### Feature 4: Intelligent Suggestion Engine (10 agents)\\n\\n**What:** Generate top 10 actionable ideas using existing code patterns\\n\\n**How:**\\n```yaml\\nPattern Recognition:\\n  1. Analyze existing code style/patterns\\n  2. Identify what works well\\n  3. Detect repeated patterns that could be DRY\\'d\\n  4. Find opportunities for new features using existing components\\n  5. Suggest architectural improvements based on current structure\\n\\nSuggestion Categories:\\n  - Missing Features (using existing patterns)\\n  - Code Improvements (refactoring opportunities)\\n  - New Tools/Utilities (based on current needs)\\n  - Architecture Enhancements (scalability/maintainability)\\n  - Quality Improvements (tests, docs, monitoring)\\n\\nPrioritization:\\n  - High Impact + Low Effort = Top priority\\n  - Leverage existing code = Higher ranking\\n  - Fill critical gaps = Elevated priority\\n```\\n\\n**Output Example:**\\n```markdown\\n## Top 10 Actionable Ideas\\n\\n### 1. User Export Feature (High Impact, Low Effort)\\n**Why:** You have User model + CSV utility in lib/\\n**How:** Combine existing UserService.get_all() + csv_writer()\\n**Effort:** 30 minutes | **Files:** 1 new endpoint, 1 test\\n\\n### 2. Automated API Documentation\\n**Why:** 8 endpoints exist but no docs\\n**How:** Add FastAPI OpenAPI auto-generation (built-in)\\n**Effort:** 15 minutes | **Files:** main.py config\\n\\n### 3. User Search Endpoint\\n**Why:** UserList.tsx has search UI but no backend\\n**How:** Add to user_service.py using existing DB patterns\\n**Effort:** 45 minutes | **Files:** 1 endpoint, 1 test\\n\\n### 4. Docker Development Environment\\n**Why:** Team setup is manual and error-prone\\n**How:** Dockerfile + docker-compose.yml for all services\\n**Effort:** 1 hour | **Files:** 2 new configs\\n\\n### 5. Reusable Form Validation Hook\\n**Why:** Validation logic repeated in 5+ components\\n**How:** Extract to custom React hook using existing validators\\n**Effort:** 30 minutes | **Files:** 1 new hook, update 5 components\\n\\n### 6. Database Migration System\\n**Why:** Models exist but schema changes are manual\\n**How:** Add Alembic, generate initial migration from models\\n**Effort:** 1 hour | **Files:** migrations/ folder, config\\n\\n### 7. Generic Error Handler Middleware\\n**Why:** Error handling duplicated across routes\\n**How:** FastAPI middleware using existing error patterns\\n**Effort:** 30 minutes | **Files:** 1 middleware, update main.py\\n\\n### 8. Logging Utility Wrapper\\n**Why:** print() statements everywhere, hard to debug\\n**How:** Structured logging using your existing config pattern\\n**Effort:** 45 minutes | **Files:** 1 logger util, update 10 files\\n\\n### 9. Health Check Endpoint\\n**Why:** No way to monitor service status\\n**How:** Simple /health endpoint checking DB + dependencies\\n**Effort:** 20 minutes | **Files:** 1 endpoint\\n\\n### 10. Component Storybook\\n**Why:** 23 components, no visual documentation\\n**How:** Storybook setup for React components\\n**Effort:** 2 hours | **Files:** Storybook config, stories per component\\n```\\n\\n### Feature 5: Token-Efficient Output Format (2 agents)\\n\\n**What:** Generate ultra-concise markdown optimized for LLM context\\n\\n**How:**\\n```yaml\\nOptimization Techniques:\\n  - Use bullet points, not prose\\n  - Abbreviate where clear (e.g., \"DB\" not \"Database\")\\n  - Group related items\\n  - Use symbols (\u2713\u2717\u25b3) instead of words\\n  - Code examples only when adding value\\n  - Omit obvious information\\n  - Prioritize actionable over descriptive\\n\\nTarget: <3000 tokens for typical project\\nCompare: /init often 20k-50k tokens\\nSavings: 85-90% token reduction\\n```\\n\\n---\\n\\n## TECHNICAL ARCHITECTURE\\n\\n### System Components\\n\\n```yaml\\narchitecture:\\n  cli_tool:                                   # 30% of effort\\n    entry_point: rapid-context\\n    commands:\\n      - analyze <path>                        # Main command\\n      - watch <path>                          # Continuous monitoring\\n      - diff <path1> <path2>                  # Compare two states\\n      - export <format>                       # JSON, Markdown, HTML\\n\\n  analysis_engine:                            # 40% of effort\\n    components:\\n      - structure_mapper:\\n          strategy: \"Directory tree + sampling\"\\n          speed: \"<2 seconds for 1000 files\"\\n\\n      - purpose_inferencer:\\n          strategy: \"Pattern matching + first-N-lines\"\\n          models: \"Convention rules + heuristics\"\\n\\n      - gap_detector:\\n          strategy: \"Expected vs Actual comparison\"\\n          patterns: \"Framework-specific templates\"\\n\\n      - suggestion_engine:\\n          strategy: \"Pattern recognition + combination\"\\n          ranking: \"Impact \u00d7 (1/Effort) \u00d7 CodeReuse\"\\n\\n  output_generator:                           # 20% of effort\\n    formats:\\n      - markdown: \"Primary, LLM-optimized\"\\n      - json: \"Machine-readable for tools\"\\n      - html: \"Human-readable reports\"\\n\\n  cache_system:                               # 10% of effort\\n    purpose: \"Incremental analysis, reuse learnings\"\\n    storage: \".rapid-context/ folder\"\\n    invalidation: \"On file changes (watch mode)\"\\n```\\n\\n### Technology Stack\\n\\n```yaml\\ntech_stack:\\n  language: Python 3.11+\\n\\n  core_libraries:\\n    - click: \"CLI framework\"\\n    - tree-sitter: \"Fast syntax parsing (optional, for advanced)\"\\n    - pathlib: \"Path operations\"\\n    - jinja2: \"Template engine for output\"\\n    - pyyaml: \"Config file support\"\\n\\n  optional_enhancements:\\n    - watchdog: \"File system monitoring\"\\n    - rich: \"Beautiful terminal output\"\\n    - pygments: \"Syntax highlighting\"\\n\\n  packaging:\\n    - poetry: \"Dependency management\"\\n    - pyinstaller: \"Single-binary distribution\"\\n```\\n\\n---\\n\\n## IMPLEMENTATION STRATEGY\\n\\n### Phase 1: Core Engine (40% of effort, 3-4 minutes)\\n\\n**Team Alpha: Structure Mapper (3 agents)**\\n```python\\n# Pseudo-implementation\\nclass StructureMapper:\\n    def map_directory(path: Path) -> StructureMap:\\n        # 1. Build file tree (os.walk)\\n        # 2. Group by extension\\n        # 3. Detect framework (check for marker files)\\n        # 4. Identify entry points (main.*, index.*, __init__.*)\\n        # 5. Return structured map\\n\\n    def sample_files(structure: StructureMap) -> Dict[str, File]:\\n        # Sample 1 file per directory per type\\n        # Priority: Entry points > Common patterns > Random\\n```\\n\\n**Team Beta: Purpose Inferencer (5 agents)**\\n```python\\nclass PurposeInferencer:\\n    def infer_purpose(file: File) -> Purpose:\\n        # 1. Read first N lines (N=10 default)\\n        # 2. Extract imports/exports\\n        # 3. Match against pattern library\\n        # 4. Assign confidence score\\n\\n    def build_dependency_graph(files: List[File]) -> Graph:\\n        # Cross-reference imports to understand relationships\\n```\\n\\n### Phase 2: Intelligence Layer (40% of effort, 3-4 minutes)\\n\\n**Team Gamma: Gap Detector (3 agents)**\\n```python\\nclass GapDetector:\\n    def detect_gaps(structure: StructureMap, purposes: Dict) -> List[Gap]:\\n        # 1. Load framework template (e.g., \"react-fastapi\")\\n        # 2. Compare expected vs actual\\n        # 3. Find missing components\\n        # 4. Identify incomplete implementations\\n```\\n\\n**Team Delta: Suggestion Engine (7 agents)**\\n```python\\nclass SuggestionEngine:\\n    def generate_suggestions(structure, purposes, gaps) -> List[Suggestion]:\\n        # 1. Pattern recognition (find reusable components)\\n        # 2. Gap filling (suggest missing pieces)\\n        # 3. Improvement opportunities (refactoring)\\n        # 4. Feature ideas (combine existing code)\\n        # 5. Rank by impact/effort/code_reuse\\n        # 6. Return top 10\\n```\\n\\n### Phase 3: Output & UX (20% of effort, 2-3 minutes)\\n\\n**Team Epsilon: Output Generator (2 agents)**\\n```python\\nclass OutputGenerator:\\n    def generate_markdown(analysis: Analysis) -> str:\\n        # Use Jinja2 templates\\n        # Optimize for token efficiency\\n        # Include only actionable information\\n\\n    def estimate_tokens(markdown: str) -> int:\\n        # Rough estimation: words * 1.3\\n        # Ensure <3k target\\n```\\n\\n---\\n\\n## REVOLUTIONARY FEATURES\\n\\n### 1. Incremental Understanding (Watch Mode)\\n```yaml\\nInnovation: \"Continuous analysis as code changes\"\\n\\nHow it works:\\n  - Initial analysis cached in .rapid-context/\\n  - File watcher detects changes\\n  - Re-analyze only changed files + dependents\\n  - Update delta report\\n\\nUse case:\\n  Developer makes changes \u2192 Auto-update understanding\\n  Agent session continues \u2192 Fresh context without re-init\\n```\\n\\n### 2. Pattern Library System\\n```yaml\\nInnovation: \"Learns common patterns, reuses knowledge\"\\n\\nPatterns detected:\\n  - \"FastAPI + SQLAlchemy\" \u2192 Expect models/, routes/, migrations/\\n  - \"React + TypeScript\" \u2192 Expect components/, hooks/, types/\\n  - \"Pytest pattern\" \u2192 test_*.py parallel to source files\\n\\nLearning:\\n  - Successful analyses cached\\n  - User corrections stored\\n  - Pattern library grows over time\\n```\\n\\n### 3. Differential Analysis\\n```yaml\\nInnovation: \"Compare two codebases or states\"\\n\\nUse cases:\\n  - Before/after refactoring\\n  - Feature branch vs main\\n  - Two different projects (identify reusable components)\\n\\nCommand: rapid-context diff ./project-v1 ./project-v2\\nOutput: What\\'s new, what\\'s removed, what\\'s changed\\n```\\n\\n### 4. Export for AI Agents\\n```yaml\\nInnovation: \"Perfect format for LLM consumption\"\\n\\nOptimizations:\\n  - Hierarchical structure (easy to skim)\\n  - Actionable focus (not just descriptive)\\n  - Token-counted (stays within budgets)\\n  - Copy-paste ready (markdown code blocks)\\n\\nIntegration:\\n  - Paste into Claude/GPT prompt\\n  - Use as project context\\n  - Feed into autonomous agents\\n```\\n\\n---\\n\\n## OUTPUT EXAMPLES\\n\\n### Example 1: Small Project (~50 files)\\n\\n```markdown\\n# Rapid Context Analysis - Todo App\\n\\n**Analyzed:** 47 files in 3.2 seconds | **Tokens:** ~1,200\\n\\n## Stack\\nReact 18 + FastAPI + SQLite | Docker ready\\n\\n## Structure\\n```\\n\u2713 Frontend (React): 18 components, 5 hooks\\n\u2713 Backend (FastAPI): 4 endpoints, 2 models\\n\u25b3 Tests: 8 files (60% coverage)\\n\u2717 Deployment: No CI/CD\\n```\\n\\n## Purpose Map\\n- `/src/App.tsx` - Main app, routing\\n- `/src/components/TodoList.tsx` - Todo display/edit\\n- `/backend/main.py` - API entry, 4 CRUD endpoints\\n- `/backend/models.py` - Todo + User models\\n\\n## Missing\\n1. User authentication (models exist, no implementation)\\n2. Database migrations (using SQLAlchemy but no Alembic)\\n3. Error handling (no global error boundary)\\n4. API tests (only frontend tested)\\n\\n## Top 5 Ideas\\n1. **Add Todo Filtering** - Frontend has search UI, no backend (20min)\\n2. **User Login** - Models ready, add JWT auth (1hr)\\n3. **Docker Compose** - Dockerfile exists, add compose (15min)\\n4. **API Docs** - Enable FastAPI OpenAPI (5min)\\n5. **Todo Categories** - Extend model + UI component pattern (45min)\\n```\\n\\n### Example 2: Large Project (~500 files)\\n\\n```markdown\\n# Rapid Context Analysis - E-commerce Platform\\n\\n**Analyzed:** 487 files in 12.8 seconds | **Tokens:** ~2,800\\n\\n## Stack\\nNext.js + NestJS + PostgreSQL + Redis | Kubernetes ready\\n\\n## Structure (Monorepo)\\n```\\n\u2713 Frontend: 78 components, 23 pages, 15 hooks\\n\u2713 Backend: 34 modules, 12 microservices\\n\u2713 Tests: 156 files (82% coverage)\\n\u2713 Infra: K8s configs, Terraform\\n\u25b3 Docs: API documented, architecture outdated\\n```\\n\\n## Microservices Map\\n1. **user-service** - Auth, profiles (NestJS + PostgreSQL)\\n2. **product-service** - Catalog, search (NestJS + Elasticsearch)\\n3. **order-service** - Cart, checkout (NestJS + PostgreSQL + Stripe)\\n4. **notification-service** - Email, SMS (NestJS + Redis queue)\\n\\n## Missing\\n1. Service mesh (microservices exist, no Istio/Linkerd)\\n2. Distributed tracing (no Jaeger/OpenTelemetry)\\n3. Rate limiting (exposed APIs lack protection)\\n4. Database backup automation (manual only)\\n5. Load testing suite (no performance benchmarks)\\n\\n## Top 10 Ideas\\n1. **Admin Dashboard** - Reuse components from customer UI (2hrs)\\n2. **Product Recommendations** - Combine order history + ML model stub (3hrs)\\n3. **Inventory Alerts** - Use existing product service + notification (1hr)\\n4. **Checkout Analytics** - Track abandonment using current events (1hr)\\n5. **Bulk Product Import** - CSV upload using existing product create (2hrs)\\n6. **User Wishlists** - New table + reuse product display components (2hrs)\\n7. **Discount Code System** - Extend order service, UI exists (3hrs)\\n8. **GraphQL Gateway** - Unify microservices with Apollo (4hrs)\\n9. **Real-time Inventory** - WebSocket on product service (2hrs)\\n10. **Multi-currency Support** - Extend order service with rates API (3hrs)\\n```\\n\\n---\\n\\n## DELIVERABLES\\n\\n```yaml\\noutputs:\\n  cli_tool:\\n    - rapid-context (executable binary)\\n    - Configuration: .rapidcontext.yml (optional customization)\\n\\n  python_library:\\n    - rapid_context/ package (importable for custom use)\\n    - API for programmatic access\\n\\n  documentation:\\n    - README.md (Quick start, examples)\\n    - CLI_REFERENCE.md (All commands, flags)\\n    - PATTERNS.md (Supported frameworks, extending patterns)\\n    - API_DOCS.md (Python library usage)\\n\\n  tests:\\n    - Unit tests (80% coverage)\\n    - Integration tests (CLI commands)\\n    - Performance benchmarks (speed tests)\\n\\n  examples:\\n    - Example analyses for common project types\\n    - Sample output formats\\n    - Integration scripts (use in CI/CD)\\n```\\n\\n---\\n\\n## SUCCESS METRICS\\n\\n```yaml\\nperformance_targets:\\n  speed:\\n    - Small project (<100 files): <5 seconds\\n    - Medium project (100-1000 files): <15 seconds\\n    - Large project (1000-5000 files): <60 seconds\\n\\n  token_efficiency:\\n    - Output size: <3000 tokens for typical project\\n    - Reduction vs /init: >85%\\n\\n  accuracy:\\n    - Structure mapping: 95%+ accuracy\\n    - Purpose inference: 80%+ accuracy\\n    - Gap detection: 70%+ recall\\n    - Suggestion relevance: 70%+ user approval\\n\\nquality_targets:\\n  - All code type-hinted (Python 3.11+)\\n  - 80%+ test coverage\\n  - Zero external dependencies for core (optional for enhancements)\\n  - Single-binary distribution option\\n  - Cross-platform (Windows, Mac, Linux)\\n```\\n\\n---\\n\\n## USAGE EXAMPLES\\n\\n### Basic Analysis\\n```bash\\n# Analyze current directory\\nrapid-context analyze .\\n\\n# Analyze specific path\\nrapid-context analyze /path/to/project\\n\\n# Output to file\\nrapid-context analyze . --output analysis.md\\n\\n# JSON format (for tools)\\nrapid-context analyze . --format json\\n```\\n\\n### Watch Mode (Continuous)\\n```bash\\n# Monitor for changes, update analysis\\nrapid-context watch .\\n\\n# Watch and serve via HTTP (for IDE integration)\\nrapid-context watch . --serve 8080\\n```\\n\\n### Differential Analysis\\n```bash\\n# Compare two states\\nrapid-context diff ./before ./after\\n\\n# Compare branches\\nrapid-context diff --git main feature-branch\\n```\\n\\n### Custom Configuration\\n```yaml\\n# .rapidcontext.yml\\nsampling:\\n  lines_per_file: 15          # Read first N lines\\n  files_per_dir: 2            # Sample N files per directory\\n\\nignore:\\n  - node_modules/\\n  - .git/\\n  - dist/\\n  - build/\\n\\npatterns:\\n  custom:\\n    - pattern: \"*_controller.py\"\\n      purpose: \"API controller\"\\n    - pattern: \"use*.tsx\"\\n      purpose: \"React custom hook\"\\n\\nsuggestions:\\n  max_count: 10\\n  min_impact: \"medium\"\\n  max_effort: \"4 hours\"\\n```\\n\\n---\\n\\n## ANTI-REQUIREMENTS\\n\\n```yaml\\ndo_not_build:\\n  - \u2717 Full AST parsing (too slow, use tree-sitter selectively)\\n  - \u2717 AI/LLM integration (keep it deterministic, fast, offline)\\n  - \u2717 Code execution (security risk, not needed)\\n  - \u2717 Full file content indexing (defeats token efficiency)\\n  - \u2717 GUI application (CLI + library only)\\n  - \u2717 Cloud service (local-first tool)\\n  - \u2717 Database requirement (filesystem + cache only)\\n```\\n\\n---\\n\\n## FUTURE ENHANCEMENTS (Out of Scope for v1.0)\\n\\n```yaml\\npotential_v2_features:\\n  - IDE integration (VSCode extension)\\n  - GitHub Action (auto-comment on PRs)\\n  - API server mode (HTTP API for tooling)\\n  - Machine learning suggestions (beyond pattern matching)\\n  - Multi-repo analysis (monorepo support)\\n  - Collaboration features (shared analyses)\\n  - Visualization (interactive graphs)\\n```\\n\\n---\\n\\n## COMPETITIVE ADVANTAGE\\n\\n**vs Claude Code /init:**\\n- **10-20x faster** (seconds vs minutes)\\n- **90% less tokens** (<3k vs 20-50k)\\n- **Gap detection** (tells you what\\'s missing)\\n- **Actionable suggestions** (not just description)\\n\\n**vs GitHub Copilot Workspace:**\\n- **Offline-first** (no cloud dependency)\\n- **Deterministic** (consistent results)\\n- **Extensible** (pattern library, customization)\\n- **Privacy** (code stays local)\\n\\n**vs Manual README:**\\n- **Always current** (generated on demand)\\n- **Comprehensive** (doesn\\'t miss hidden patterns)\\n- **Structured** (consistent format)\\n- **Actionable** (includes suggestions, not just description)\\n\\n---\\n\\n## FINAL NOTES\\n\\nThis tool represents a **paradigm shift** in how AI agents understand codebases:\\n\\n**Traditional:** Read everything \u2192 Slow, expensive\\n**Rapid Context:** Sample smartly \u2192 Fast, cheap, good enough\\n\\n**Key Insight:** You don\\'t need to read every line to understand what a project does. Conventions, structure, and sampling give you 80% of the picture in 10% of the time.\\n\\n**Target Users:**\\n1. AI Agents (Claude, GPT) - Fast context loading\\n2. Developers - Quick codebase orientation\\n3. Teams - Onboarding new members\\n4. Tools - Automated analysis in CI/CD\\n\\n**Success Definition:**\\nWhen developers and AI agents reach for Rapid Context FIRST before diving into code - we\\'ve won.\\n\\n---\\n\\n**END OF SPECIFICATION**\\n\\n*Build this in under 10 minutes. Make it blazing fast. Make it indispensable.*\\n')"
  },
  "metadata": {
    "phase": "specification"
  },
  "version": "1.0"
}