# ðŸ“š SOVEREIGN LLM-NATIVE - Usage Guide

## Hur man anvÃ¤nder dessa system-prompts pÃ¥ olika plattformar

---

## ðŸŸ£ CLAUDE (Anthropic)

### Claude Projects (Rekommenderat)
1. GÃ¥ till **Projects** i Claude.ai
2. Skapa nytt projekt
3. Under **Project Knowledge**, ladda upp en av SOVEREIGN-filerna
4. Alternativt: Klistra in i **Custom Instructions**

### Per-konversation
Klistra in hela system-prompten som fÃ¶rsta meddelande:
```
[Klistra in SOVEREIGN_SYSTEM_PROMPT.md]

---

Nu Ã¤r du redo. Min fÃ¶rsta uppgift: [din uppgift]
```

### Tips fÃ¶r Claude
- Claude Ã¤r bra pÃ¥ att fÃ¶lja komplexa instruktioner
- Fungerar utmÃ¤rkt med alla SOVEREIGN-varianter
- AnvÃ¤nd `/meta` fÃ¶r att se orchestration-processen

---

## ðŸŸ¢ CHATGPT (OpenAI)

### Custom GPT (BÃ¤st)
1. GÃ¥ till **My GPTs** â†’ **Create a GPT**
2. Under **Configure** â†’ **Instructions**, klistra in vald SOVEREIGN-prompt
3. Namnge GPT:n (t.ex. "SOVEREIGN:CODE")
4. Spara och anvÃ¤nd

### System Prompt via API
```python
import openai

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {
            "role": "system",
            "content": open("SYSTEM_PROMPT_COMPACT.md").read()
        },
        {
            "role": "user", 
            "content": "Din uppgift hÃ¤r"
        }
    ]
)
```

### Per-konversation (ChatGPT web)
BÃ¶rja konversationen med:
```
FrÃ¥n och med nu vill jag att du agerar enligt detta system:

[Klistra in SYSTEM_PROMPT_COMPACT.md]

BekrÃ¤fta att du fÃ¶rstÃ¥tt genom att svara "SOVEREIGN initialized."
```

### Tips fÃ¶r GPT
- AnvÃ¤nd COMPACT-versionen (kortare context)
- GPT-4 fungerar bÃ¤st (GPT-3.5 kan tappa instruktioner)
- Repetera viktiga instruktioner om lÃ¥nga konversationer

---

## ðŸ”µ GEMINI (Google)

### Gemini Gems (Google AI Studio)
1. GÃ¥ till **AI Studio** â†’ **Create New** â†’ **Gem**
2. Under **System Instructions**, klistra in SOVEREIGN-prompten
3. Testa i playground
4. Publicera som Gem

### DirektanvÃ¤ndning
```
Agera som fÃ¶ljande system fÃ¶r hela denna konversation:

[SYSTEM_PROMPT_COMPACT.md innehÃ¥ll]

---

UPPGIFT: [din uppgift]
```

### Tips fÃ¶r Gemini
- Gemini hanterar lÃ¤ngre contexts bra
- Kan anvÃ¤nda full-version av prompten
- Bra pÃ¥ att fÃ¶lja strukturerade outputs

---

## ðŸ”´ LLAMA / Open Source

### Via Ollama
```bash
# Skapa modelfile
cat > sovereign.modelfile << 'EOF'
FROM llama3
SYSTEM """
[SYSTEM_PROMPT_COMPACT.md innehÃ¥ll]
"""
PARAMETER temperature 0.7
EOF

# Skapa modellen
ollama create sovereign -f sovereign.modelfile

# KÃ¶r
ollama run sovereign
```

### Via LangChain
```python
from langchain.chat_models import ChatOllama
from langchain.schema import SystemMessage, HumanMessage

sovereign_prompt = open("SYSTEM_PROMPT_COMPACT.md").read()

chat = ChatOllama(model="llama3")
response = chat([
    SystemMessage(content=sovereign_prompt),
    HumanMessage(content="Din uppgift")
])
```

---

## ðŸŸ¡ API-INTEGRATION (Alla plattformar)

### Python Template
```python
"""
Universal SOVEREIGN integration template.
Works with OpenAI, Anthropic, Google, or local models.
"""

from pathlib import Path

class SovereignOrchestrator:
    def __init__(self, client, model: str, variant: str = "base"):
        self.client = client
        self.model = model
        
        # Load appropriate system prompt
        prompts = {
            "base": "SYSTEM_PROMPT_COMPACT.md",
            "code": "SOVEREIGN_CODE.md",
            "seo": "SOVEREIGN_SEO.md",
            "meta": "SOVEREIGN_META.md"
        }
        
        prompt_file = Path(__file__).parent / prompts.get(variant, prompts["base"])
        self.system_prompt = prompt_file.read_text()
    
    def execute(self, task: str, show_process: bool = False) -> str:
        """Execute a task through SOVEREIGN orchestration."""
        
        # Add visibility command if requested
        if show_process:
            task = f"/meta\n\n{task}"
        
        # Call appropriate API
        # (Implement based on your client type)
        response = self._call_api(task)
        
        return response
    
    def _call_api(self, task: str) -> str:
        # OpenAI style
        if hasattr(self.client, 'chat'):
            return self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": task}
                ]
            ).choices[0].message.content
        
        # Anthropic style
        elif hasattr(self.client, 'messages'):
            return self.client.messages.create(
                model=self.model,
                system=self.system_prompt,
                messages=[{"role": "user", "content": task}]
            ).content[0].text
        
        raise ValueError("Unknown client type")


# Usage
# orchestrator = SovereignOrchestrator(client, "gpt-4", variant="code")
# result = orchestrator.execute("Build a REST API for user management")
```

---

## ðŸŽ¯ VILKEN VARIANT SKA JAG ANVÃ„NDA?

| Uppgift | Variant | Fil |
|---------|---------|-----|
| Generell anvÃ¤ndning | Base | `SYSTEM_PROMPT_COMPACT.md` |
| Programmering | Code | `SOVEREIGN_CODE.md` |
| SEO & Content | SEO | `SOVEREIGN_SEO.md` |
| Bygga AI-system | Meta | `SOVEREIGN_META.md` |
| LÃ¤ra sig systemet | Full | `SOVEREIGN_SYSTEM_PROMPT.md` |

---

## ðŸ’¡ BEST PRACTICES

### 1. BÃ¶rja med COMPACT
Den kompakta versionen fungerar pÃ¥ alla plattformar och fÃ¶rbrukar mindre tokens.

### 2. Specialisera vid behov
Om du mest jobbar med kod, anvÃ¤nd SOVEREIGN:CODE permanent.

### 3. AnvÃ¤nd commands
Kommandona (`/preflight`, `/iterate`, `/meta`) ger dig kontroll:
- `/preflight` - Se analysen innan execution
- `/meta` - Se hela processen
- `/direct` - Skippa orchestration fÃ¶r enkla saker

### 4. Iterera pÃ¥ prompten
LÃ¤gg till egna regler baserat pÃ¥ dina behov:
```
[Original SOVEREIGN prompt]

## ADDITIONAL RULES FOR MY USE CASE
- Alltid inkludera TypeScript types
- Prioritera readability Ã¶ver performance
- AnvÃ¤nd svenska kommentarer
```

### 5. Kombinera varianter
FÃ¶r komplexa projekt, anvÃ¤nd META fÃ¶r att designa, CODE fÃ¶r implementation:
```
Konversation 1 (SOVEREIGN:META): Design system architecture
Konversation 2 (SOVEREIGN:CODE): Implement each component
```

---

## ðŸ”§ TROUBLESHOOTING

### "Modellen fÃ¶ljer inte instruktionerna"
- Prova COMPACT-versionen (kortare)
- Repetera viktigaste reglerna i slutet av prompten
- AnvÃ¤nd starkare sprÃ¥k: "ALWAYS", "NEVER", "CRITICAL"

### "Output Ã¤r fÃ¶r kort/lÃ¥ng"
- LÃ¤gg till explicit lÃ¤ngdkrav i prompten
- AnvÃ¤nd `/minimal` eller be om "comprehensive"

### "Orchestration syns inte"
- AnvÃ¤nd `/meta` eller `/iterate` commands
- LÃ¤gg till: "Show your thinking process"

### "Token limit nÃ¥s"
- AnvÃ¤nd COMPACT-versionen
- Ta bort unused patterns frÃ¥n prompten
- Splitta till flera konversationer

---

## ðŸ“¦ FILÃ–VERSIKT

```
SOVEREIGN_LLM/
â”œâ”€â”€ SOVEREIGN_SYSTEM_PROMPT.md    # Full documentation (learning)
â”œâ”€â”€ SYSTEM_PROMPT_COMPACT.md      # Production-ready (recommended)
â”œâ”€â”€ SOVEREIGN_CODE.md             # Code specialization
â”œâ”€â”€ SOVEREIGN_SEO.md              # SEO specialization
â”œâ”€â”€ SOVEREIGN_META.md             # Meta/architecture specialization
â””â”€â”€ USAGE_GUIDE.md                # This file
```

---

**Du Ã¤r nu redo att anvÃ¤nda SOVEREIGN pÃ¥ valfri LLM-plattform!** ðŸš€
